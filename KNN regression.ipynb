{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febbc247",
   "metadata": {},
   "source": [
    "## Implementation of KNN Regressor function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3322de",
   "metadata": {},
   "source": [
    "Background: A\tKNN\tregressor\tis\tsimilar\tto\ta\tKNN\tclassifier\t(covered\tin\tActivity 1.1) in\tthat\tit\tfinds\tthe\tK\tnearest\tneighbors\tand\testimates\tthe\tvalue of\tthe\tgiven test point based on the values of its neighbours. The main difference between\tKNN regression and KNN classification is that KNN classifier returns the label\t\n",
    "that has\tthe\tmajority\tvote\tin\tthe\tneighborhood,\twhilst\tKNN\tregressor\treturns\tthe\taverage\tof\tthe\tneighborsâ€™\tvalues. In\tActivity\t1\tof\tModule\t1,\twe\tuse\tthe\tnumber\tof\tmis-classifications as the measurement of training and testing errors in KNN classifier.\tFor\tKNN\tregressor,\tyou\tneed\tto\tchoose\tanother\terror\tfunction\t(e.g.,\tthe\tsum of the squares of the errors) as the measurement of training errors and\ttesting\terrors.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c1c29",
   "metadata": {},
   "source": [
    "### 1. Import all the necessary library and explore the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773f412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n"
     ]
    }
   ],
   "source": [
    "#Install all the necessary library\n",
    "#install.packages(\"reshape2\")\n",
    "#install.packages(\"ggplot2\")\n",
    "#install.packages(\"corrplot\")\n",
    "\n",
    "#Import the library\n",
    "library(reshape2) #For reshape the file\n",
    "library(ggplot2) #For data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01c827d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1960.0</td><td>0.71  </td></tr>\n",
       "\t<tr><td>1960.5</td><td>0.85  </td></tr>\n",
       "\t<tr><td>1961.0</td><td>0.61  </td></tr>\n",
       "\t<tr><td>1961.5</td><td>0.92  </td></tr>\n",
       "\t<tr><td>1962.0</td><td>0.72  </td></tr>\n",
       "\t<tr><td>1962.5</td><td>0.92  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " x1 & y\\\\\n",
       "\\hline\n",
       "\t 1960.0 & 0.71  \\\\\n",
       "\t 1960.5 & 0.85  \\\\\n",
       "\t 1961.0 & 0.61  \\\\\n",
       "\t 1961.5 & 0.92  \\\\\n",
       "\t 1962.0 & 0.72  \\\\\n",
       "\t 1962.5 & 0.92  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| x1 | y |\n",
       "|---|---|\n",
       "| 1960.0 | 0.71   |\n",
       "| 1960.5 | 0.85   |\n",
       "| 1961.0 | 0.61   |\n",
       "| 1961.5 | 0.92   |\n",
       "| 1962.0 | 0.72   |\n",
       "| 1962.5 | 0.92   |\n",
       "\n"
      ],
      "text/plain": [
       "  x1     y   \n",
       "1 1960.0 0.71\n",
       "2 1960.5 0.85\n",
       "3 1961.0 0.61\n",
       "4 1961.5 0.92\n",
       "5 1962.0 0.72\n",
       "6 1962.5 0.92"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1960.25</td><td>0.63   </td></tr>\n",
       "\t<tr><td>1960.75</td><td>0.44   </td></tr>\n",
       "\t<tr><td>1961.25</td><td>0.69   </td></tr>\n",
       "\t<tr><td>1961.75</td><td>0.55   </td></tr>\n",
       "\t<tr><td>1962.25</td><td>0.77   </td></tr>\n",
       "\t<tr><td>1962.75</td><td>0.60   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " x1 & y\\\\\n",
       "\\hline\n",
       "\t 1960.25 & 0.63   \\\\\n",
       "\t 1960.75 & 0.44   \\\\\n",
       "\t 1961.25 & 0.69   \\\\\n",
       "\t 1961.75 & 0.55   \\\\\n",
       "\t 1962.25 & 0.77   \\\\\n",
       "\t 1962.75 & 0.60   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| x1 | y |\n",
       "|---|---|\n",
       "| 1960.25 | 0.63    |\n",
       "| 1960.75 | 0.44    |\n",
       "| 1961.25 | 0.69    |\n",
       "| 1961.75 | 0.55    |\n",
       "| 1962.25 | 0.77    |\n",
       "| 1962.75 | 0.60    |\n",
       "\n"
      ],
      "text/plain": [
       "  x1      y   \n",
       "1 1960.25 0.63\n",
       "2 1960.75 0.44\n",
       "3 1961.25 0.69\n",
       "4 1961.75 0.55\n",
       "5 1962.25 0.77\n",
       "6 1962.75 0.60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import the training and testing csv file\n",
    "train <- read.csv('Task1A_train.csv')\n",
    "test <- read.csv('Task1A_test.csv')\n",
    "\n",
    "#Explore the train and test dataset\n",
    "head(train)\n",
    "head(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76819834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1960.0</td></tr>\n",
       "\t<tr><td>1960.5</td></tr>\n",
       "\t<tr><td>1961.0</td></tr>\n",
       "\t<tr><td>1961.5</td></tr>\n",
       "\t<tr><td>1962.0</td></tr>\n",
       "\t<tr><td>1962.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 1960.0\\\\\n",
       "\t 1960.5\\\\\n",
       "\t 1961.0\\\\\n",
       "\t 1961.5\\\\\n",
       "\t 1962.0\\\\\n",
       "\t 1962.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1960.0 |\n",
       "| 1960.5 |\n",
       "| 1961.0 |\n",
       "| 1961.5 |\n",
       "| 1962.0 |\n",
       "| 1962.5 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]  \n",
       "[1,] 1960.0\n",
       "[2,] 1960.5\n",
       "[3,] 1961.0\n",
       "[4,] 1961.5\n",
       "[5,] 1962.0\n",
       "[6,] 1962.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prepare the dataset by separate the actual result and the predictor\n",
    "train_data = as.matrix(train[,-2]) \n",
    "train_label = as.matrix(train[,2])\n",
    "test_data = as.matrix(test[,-2])\n",
    "test_label = as.matrix(test[,2])\n",
    "\n",
    "#All the train set x value after the y have been removed\n",
    "head(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d0dfd",
   "metadata": {},
   "source": [
    "### 2. Create KNN regressor function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173e747",
   "metadata": {},
   "source": [
    "1. Implement the\tKNN\tregressor\tfunction:knn(train.data,\ttrain.label,\ttest.data,\tK=3)\n",
    "which\ttakes\tthe\ttraining\tdata\tand\ttheir\tlabels\t(continuous\tvalues),\tthe\ttest\n",
    "set,\tand\t the\tsize\tof\t the\tneighborhood\t (K).\t It\tshould\treturn\t the\tregressed\n",
    "values\t for\t the\t test\t data\t points.\t Note\t that,\t you\t need\t to\t use\t a\t distance\n",
    "function\tto\tchoose\tthe\tneighbors.\tThe\tdistance\t function\tused\tto\tmeasure\n",
    "the\tdistance\tbetween\ta\tpair\tof\tdata\tpoints\tis\tEuclidean\tdistance\tfunction. \n",
    "\n",
    "In this part, the KNN regressor function will be created with the same approach of KNN classifier. The only difference is that the knn regressor will return the mean value of the datapoint that near yhe k-neighbour value. This is how the function created:\n",
    "- It starts with choosing a K value\n",
    "- Calculate the distance between data point with K with euclidean distance approach\n",
    "- Then getting an average of distance between point and k-value \n",
    "- return the mean from the neighbour point as a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa923d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derieved the KNN function from the tutorial activity 1\n",
    "# KNN function (distance should be one of euclidean, maximum, manhattan, canberra, binary or minkowski)\n",
    "knn <- function(train.data, train.label, test.data, K=3, distance = 'euclidean'){\n",
    "    ## count number of train and test samples\n",
    "    train.len <- nrow(train.data)\n",
    "    test.len <- nrow(test.data)\n",
    "    \n",
    "    ## calculate distances between samples\n",
    "    dist <- as.matrix(dist(rbind(test.data, train.data), method= distance))[1:test.len, (test.len+1):(test.len+train.len)]\n",
    "    \n",
    "    test.label <- as.matrix(nrow(test.data))\n",
    "    ## for each test sample...\n",
    "    for (i in 1:test.len){\n",
    "        ### ...find its K nearest neighbours from training sample...\n",
    "        nn <- as.data.frame(sort(dist[i,], index.return = TRUE))[1:K,2]\n",
    "        \n",
    "        ###... and calculate mean from the neighbour\n",
    "        test.label[i] <- mean(train.label[nn])\n",
    "    }\n",
    "    \n",
    "    ## return the mean as output\n",
    "    return (test.label)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8b5680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.723333333333333</li>\n",
       "\t<li>0.723333333333333</li>\n",
       "\t<li>0.793333333333333</li>\n",
       "\t<li>0.75</li>\n",
       "\t<li>0.853333333333333</li>\n",
       "\t<li>0.823333333333333</li>\n",
       "\t<li>0.916666666666667</li>\n",
       "\t<li>0.916666666666667</li>\n",
       "\t<li>1.05333333333333</li>\n",
       "\t<li>1.10666666666667</li>\n",
       "\t<li>1.28333333333333</li>\n",
       "\t<li>1.29</li>\n",
       "\t<li>1.52333333333333</li>\n",
       "\t<li>1.55</li>\n",
       "\t<li>1.74</li>\n",
       "\t<li>1.63</li>\n",
       "\t<li>1.9</li>\n",
       "\t<li>2.01</li>\n",
       "\t<li>2.4</li>\n",
       "\t<li>2.55</li>\n",
       "\t<li>3.06</li>\n",
       "\t<li>3.36</li>\n",
       "\t<li>3.87</li>\n",
       "\t<li>4.26</li>\n",
       "\t<li>4.74</li>\n",
       "\t<li>5.16</li>\n",
       "\t<li>5.73</li>\n",
       "\t<li>6.06</li>\n",
       "\t<li>6.51</li>\n",
       "\t<li>6.63</li>\n",
       "\t<li>7.23</li>\n",
       "\t<li>7.5</li>\n",
       "\t<li>7.95</li>\n",
       "\t<li>8.52</li>\n",
       "\t<li>9.12</li>\n",
       "\t<li>10.32</li>\n",
       "\t<li>11.19</li>\n",
       "\t<li>12.69</li>\n",
       "\t<li>13.68</li>\n",
       "\t<li>15.03</li>\n",
       "\t<li>15.69</li>\n",
       "\t<li>15.69</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.723333333333333\n",
       "\\item 0.723333333333333\n",
       "\\item 0.793333333333333\n",
       "\\item 0.75\n",
       "\\item 0.853333333333333\n",
       "\\item 0.823333333333333\n",
       "\\item 0.916666666666667\n",
       "\\item 0.916666666666667\n",
       "\\item 1.05333333333333\n",
       "\\item 1.10666666666667\n",
       "\\item 1.28333333333333\n",
       "\\item 1.29\n",
       "\\item 1.52333333333333\n",
       "\\item 1.55\n",
       "\\item 1.74\n",
       "\\item 1.63\n",
       "\\item 1.9\n",
       "\\item 2.01\n",
       "\\item 2.4\n",
       "\\item 2.55\n",
       "\\item 3.06\n",
       "\\item 3.36\n",
       "\\item 3.87\n",
       "\\item 4.26\n",
       "\\item 4.74\n",
       "\\item 5.16\n",
       "\\item 5.73\n",
       "\\item 6.06\n",
       "\\item 6.51\n",
       "\\item 6.63\n",
       "\\item 7.23\n",
       "\\item 7.5\n",
       "\\item 7.95\n",
       "\\item 8.52\n",
       "\\item 9.12\n",
       "\\item 10.32\n",
       "\\item 11.19\n",
       "\\item 12.69\n",
       "\\item 13.68\n",
       "\\item 15.03\n",
       "\\item 15.69\n",
       "\\item 15.69\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.723333333333333\n",
       "2. 0.723333333333333\n",
       "3. 0.793333333333333\n",
       "4. 0.75\n",
       "5. 0.853333333333333\n",
       "6. 0.823333333333333\n",
       "7. 0.916666666666667\n",
       "8. 0.916666666666667\n",
       "9. 1.05333333333333\n",
       "10. 1.10666666666667\n",
       "11. 1.28333333333333\n",
       "12. 1.29\n",
       "13. 1.52333333333333\n",
       "14. 1.55\n",
       "15. 1.74\n",
       "16. 1.63\n",
       "17. 1.9\n",
       "18. 2.01\n",
       "19. 2.4\n",
       "20. 2.55\n",
       "21. 3.06\n",
       "22. 3.36\n",
       "23. 3.87\n",
       "24. 4.26\n",
       "25. 4.74\n",
       "26. 5.16\n",
       "27. 5.73\n",
       "28. 6.06\n",
       "29. 6.51\n",
       "30. 6.63\n",
       "31. 7.23\n",
       "32. 7.5\n",
       "33. 7.95\n",
       "34. 8.52\n",
       "35. 9.12\n",
       "36. 10.32\n",
       "37. 11.19\n",
       "38. 12.69\n",
       "39. 13.68\n",
       "40. 15.03\n",
       "41. 15.69\n",
       "42. 15.69\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  0.7233333  0.7233333  0.7933333  0.7500000  0.8533333  0.8233333\n",
       " [7]  0.9166667  0.9166667  1.0533333  1.1066667  1.2833333  1.2900000\n",
       "[13]  1.5233333  1.5500000  1.7400000  1.6300000  1.9000000  2.0100000\n",
       "[19]  2.4000000  2.5500000  3.0600000  3.3600000  3.8700000  4.2600000\n",
       "[25]  4.7400000  5.1600000  5.7300000  6.0600000  6.5100000  6.6300000\n",
       "[31]  7.2300000  7.5000000  7.9500000  8.5200000  9.1200000 10.3200000\n",
       "[37] 11.1900000 12.6900000 13.6800000 15.0300000 15.6900000 15.6900000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test whether the function is work\n",
    "knn(train_data, train_label, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7737ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error function for the regression it will be mean-square error which is a mean of sum of square or mse\n",
    "#formula sum of (y_real-y_pred)**/all of sample\n",
    "mse <- function(a,b){\n",
    "    mse = sum((a - b)^2/ nrow(b))\n",
    "    return(mse)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b27ea",
   "metadata": {},
   "source": [
    "### Plot training and testing error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc875f2",
   "metadata": {},
   "source": [
    "Plot the\ttraining and\tthe\ttesting\terrors\tversus\t1/K for\tK=1,..,20 in one\tplot, using\t the Task1A_train.csv and\tTask1A_test.csv datasets provided for this assignment. Save\tthe\tplot in\tyour Jupyter Notebook\t file\t for\n",
    "Question\t1. Report\tyour\tchosen\terror\t function\tin\tyour\t Jupyter\tNotebook\n",
    "file.\n",
    "\n",
    "Firstly, it will be started by creating a dataframe consist of k 1:20, and using the function mse to calculate the error from both training_set and testing_set after applied a knn regressor function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5cd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for stroing the training and testing dataset after mse is calculate from the prediction of knn regressor\n",
    "error <- data.frame('K'=1:20, 'train'=rep(0,20), 'test'=rep(0,20))\n",
    "for (k in 1:20){\n",
    "    error[k,'train'] <- mse(knn(train_data, train_label, train_data, K=k),train_label)\n",
    "    error[k,'test'] <-  mse(knn(train_data, train_label, test_data, K=k),test_label)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ce6e4",
   "metadata": {},
   "source": [
    "Once the error is calculated and stored in the dataframe, it will be used for creating a plot in order to compare the differences between training&testing mse as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83dcdd24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAv8RNTU1oaGh8\nfHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enr6+vw8PD4dm3////ccKm3AAAACXBI\nWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2di3ai2hZEjcnp9DMP//9jj29ZqAiszbYKZt1x\n+5i0TiubNRtFMasNISSd1bMLEDKHIBIhBYJIhBQIIhFSIIhESIEgEiEFgkiEFAgiEVIgiERI\ngSASIQUyRqQ/P9ar1ev716g7/PqxvW0hVr87WTVS9m4IOWXEaP13mso/Y+5wd+u3Qqx+d4JI\nZPoMH61fq/Vu6j9+rVb/xtxh81ZJVr87QR8yfYYP2Xr1cbjwa/VjzB027zHJ6ncniESmz/Ah\nu8zl7tLxq+PFn+vV63YX82v7n1+Nm/zbPhFa//i3OT3MusPaPmN6W61+trmbzfvr9pHa38PX\nX6+r/7YX/m6v+RYeD/a4kwbhDLrc7PI9QoZmuEhvq/fm7Zsi/dxP8N8f+/9cTPpzeR7UmvHI\n2rzv//ZnW6T15WnUarV9+rO9ze/Dtxq3vn8nbZH2hBOocbPz9wgZnOEifez+Bf99eg4SRNo9\n4XlfrQ//OR81+7d142vztbXkY9Ma68jaXvH31pF1S6Sf253U7s+3/ddvX/tr7nZQ/94uxyg6\n7qQt0p5wBjVudvweIcMz4vnDx+FQ23/7IQ4i7b7zdTwCdxnf9+O/8j/2/41jHVg/Dnux3y2R\nXldfZ+B2f3dA7r/1dXkg1nEn8aDdkXAGNW52/B4hwzPqifjXn59vxwPMQaTLwDdn+fV4ROFj\nv5NqP/VvsNYnPdrPkTb/9le6fP16dTy7407aIjXB4WYclSCjM352tk/3f7YPNpwubppTeb7U\nHOQO1hXs1/pag7ZIHXfSfmh3s2XjPgkZnsGzc5m2r9U6KdJtVhv2a7u/ev/9cWN/cqsWIpFn\nZPDsNJ7gXx/+Pl3cNKfy/qOu26z2Q7vX07Oay63XV6/fdj6021x/xUM7UjSDZ+f3+XDc790T\nm8MToz9dIr0fX2y9Pg7QYq0Pxvy6POFqcP80RfpxQP67vA/o/p10ihRuhkhkdIbPzttq/Xs7\n5B/v+8Nzb6v/vjZ/2kesN82p3D4oez8cYv63aU1rZP3afnV4iShwX3cH8w4Xzwcf9q/3/Ftf\n9mgdd9IlUrgZIpHRGT47H2+nJ/q7l3f+Hl4Y7RIpvOgZpzWyji/I/re7SoP763Sdv5db/+l6\nQfb+Uburlq0XZAcvBiGHjJmdP//tT304PE35+7pa33hXT5jKxttw2tMaWJu//63W74erXLi7\no3brH3//7F40Ot/64731NqT7d9IpUnyL0IjFIGQXxdlhoIldFGcWkYhdFGcWkYhdFGcWkYhd\nmFlCCgSRCCkQRCKkQBCJkAJBJEIKBJEIKRBEIqRAnizSpz5xgUCDiuV/5mQQCWAFoj4wG0QC\nWIGoD8wGkQBWIOoDs0EkgBWI+sBsEAlgBaI+MBtEAliBqA/MBpEAViDqA7NBJIAViPrAbBAJ\nYAWiPjAbRAJYgagPzAaRAFYg6gOzQSSAFYj6wGwQCWAFoj4wG0QCWIGoD8wGkQBWIOoDs0Ek\ngBWI+sBsEAlgBaI+MBtEAliBqA/MBpEAViDqA7NBJIAViPrAbBAJYAWiPjAbRAJYgagPzAaR\nAFYg6gOzQSSAFYj6wGwQCWAFoj4wG0QCWIGoD8wGkQBWIOoDs0EkgBWI+sBsEAlgBaI+MBtE\nAliBqA/MBpEAViDqA7NBJIAViPrAbBAJYAWiPjCbwiJ9D7w+M6AINKiISDHMgCLQoCIixTAD\nikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiI\nSDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDiogUwwwo\nAg0qIlIMM6AINKhoL9Jnd74f/D0hNTKJK51hjwSwAlEfmA0iAaxA1Admg0gAKxD1gdkgEsAK\nRH1gNogEsAJRH5gNIgGsQNQHZoNIACsQ9YHZIBLACkR9YDaIBLACUR+YDSIBrEDUB2ZT+kP0\nB5rEDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyA\nItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoi\nUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOK\nQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhI\nMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgC\nDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLF\nMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKsxdpoEnMgCLQoCIixTAD\nikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiI\nSDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDip4irQcA\nEckfaFDRUqQ1Ii0LaFDRUaQ1e6SFAQ0qGoq05qHd0oAGFe1F+nyU74fXIGTqTGjMnTwUab1h\nj7Q0oEFFuz3S+vxHzyCSP9Cgop9Ih/QHIpI/0KCinUj7sEdaFtCgIiLFMAOKQIOKiBTDDCgC\nDSp6ijQkiOQPNKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIi\nxTADikCDiogUwwwoAg0qIlIMM6AINKg4f5GGmcQMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUw\nA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSo\niEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMM\nKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAi\nIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4oLEGmQScyAItCgIiLF\nMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0\nqIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTD\nDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCg\nIiLFMAOKQIOKSxBpiEnMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIi\nxTADikCDiogUwwwoAg0qIlIMM6AINKhoL9Jnj3z3uRIh02USVzrDHglgBaI+MBtEAliBqA/M\nBpEAViDqA7NBJIAViPrAbBAJYAWiPjAbRAJYgagPzAaRAFYg6gOzQSSAFYj6wGwQCWAFoj4w\nG0QCWIGoD8wGkQBWIOoDs0EkgBWI+sBsEAlgBaI+MJspRBpgEjOgCDSoiEgxzIAi0KAiIsUw\nA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSo\niEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMM\nKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KDi\nMkTqbxIzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLF\nMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0\nqIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTD\nDCgCDSoiUgwzoAg0qIhIMcyAItCg4kJE6m0SM6AINKiISDHMgCLQoCIixTADikCDiogUwwwo\nAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIi\nxTADikCDioYirbcZjEUkZ6BBRT+R1uc/hgSRnIEGFREphhlQBBpU9BNpH0RaFNCgor1In/3y\n3fN6hEyRqXS5nx4icbBhaUCDivZ7pJ5BJGegQUVEimEGFIEGFf1E4qjd8oAGFREphhlQBBpU\n9BNp3Dsb+prEDCgCDSoaijQuiGQMNKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AI\nNKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDiogU\nwwwoAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQ\noCIixTADikCDiogUwwwoAg0qLkakniYxA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAi\nIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOg\nCDSoiEgxzIAi0KAiIsUwA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4rL\nEamfScyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTD\nDCgCDSoiUgwzoAg0qIhIMcyAItCgIiLFMAOKQIOKiBTDDCgCDSoiUgwzoAg0qIhIMcyAItCg\n4oJE6mUSM6AINKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIi\nxTADikCDiogUwwwoAg0qIlIMM6AINKiISDHMgCLQoCIixTADikCDiogUwwwoAg0qLkmkPiYx\nA4pAg4qIFMMMKAINKiJSDDOgCDSoiEgxzIAi0KAiIsUwA4pAg4r2In0OyPeQKxNSLpO40hn2\nSAArEPWB2SASwApEfWA2iASwAlEfmA0iAaxA1Admg0gAKxD1gdkgEsAKRH1gNogEsAJRH5jN\nlCL1MIkZUAQaVESkGGZAEWhQUV2ktx8l4YjkCTSoqC7SuugeCpE8gQYV1UX69/b+UQ6OSJ5A\ng4rqIq3OKQFHJE+gQUVEimEGFIEGFdVFKhtE8gQaVKwv0gNTEAlgBaI+sJ2hYrSv//X+ulq9\nvn8VKYNInkCDiuoifawPz5DWRY7dIZIn0KDi1CLtDxNs/7c6Xtybsvv6nmCt7/9YvW0V+nhb\nFXlhFpE8gQYVU8Dv2wnX2btzFOhoUePr61wdtYv/zQWRPIEGFas8tFs1v1pdnLp3/eaXiATQ\noWJNkQ6P7YaJVPah3WOTmAFFoEHFiiKdnyANEanswQZE8gQaVKwnUvM50vnr29dvpujhb0Ty\nBBpUrCvS8Id2hYNIlkCDitOLtD/83bg0TKSy5yMhkifQoKL6e+3Kno+ESJ5Ag4rqIpU9HwmR\nPIEGFdVFKnsaBSJ5Ag0qIlIMM6AINKioLlLhIJIl0KCiukgctQM4BVEfmE3ho3Yv8UtEsgQa\nVFQXKXvUDpHmADSoqC5S9mADIs0BaFARkWKYAUWgQUV1kbJpifTQJGZAEWhQEZFimAFFoEFF\nfZF+/bd9WPf2byQOkeYANKioLtLX6+HjU1Z/x+EQaQ5Ag4rqIv1Yve/OYvq9ehuHQ6Q5AA0q\nqou0Wl3+PyaINAegQUVEimEGFIEGFdVFOj60ex/7KUKINAegQcXJRbq1J+nau7QPNiQ/RQiR\n5gA0qKgu0mbzM/UpQog0B6BBxalFOn4o5PEtPvGr2zcoe/+INAegQcUU8OV2wnVaH/t9+e+d\nIBLACkR9YDtXIm0QCeDTifrAdg6fC3n6lS6XDy/uun7BINIcgAYV6+2Rjl92/EaX8/ULpi3S\nI5OYAUWgQcXaIj37ORIiOQINKtZ/joRIAJ9P1Ae2c+Pwd8cvvkQkgFWI+sBsEKk6sP2KRTpL\nXEREilneDLy8fB5fESyGXN4iIlI7S5uBnT6f58uFbFraIk4CzAaRKgIP3nzGb+VtWtYiTgTM\nBpHqAV/uAZM2LWoRpwJmU/pD9Ae+tWFBM3BW5Q5wvE0LWsTpgNkgUh1gw5Eu4I23IT/OYhZx\nSmA2iFQF2FyWx8CBNi1lEScFZoNIFYDRip7A/jYtYxEnBmaDSJMD2zoMAfayaQmLODkwm6lF\nemDS/Gfg2oPBwEc2zX8RKwCzQaRpgTcEGAfssGn2i1gDmA0iTQm8OfoJ4G2bZr6IdYDZINJ0\nwDt7kGzDK5tmvYi1gNkg0mTAe09ryhxPb9g050WsBszmsUjrbfrzEOmY+4cHCr7n6GDTfBex\nIjCbhyKtz3/0CiLt03WUrfh5GcVPcBJZxKrAbBBpAmD3YE/RsLBNCotYGZhNv+dIiDQkDyZ6\nsoblbBJYxNrAbIaK9PkgL+1vfD+6xdzycrUEle9+l6dWEMhUutxPL5E42NA7PXYJNRqqneGk\nD8wGkYoC+wxvtYZCZzjpA7PpI9IAj5YtUr+xrdtwlE36c+8o0hCPlixS33l9QsOhNunPvaFI\ngzy68dim06T5iNR/UJ/XsLdN+nPvJ9J6PeitDUsV6ZkntBY/wclg7v1EGphlimT2uOmhTc+v\nWB2YDSLlgQOfzIsMVZdNIhVrArNBpDTw6R/6U/wEJ6mKlYDZIFISOINjy9c2yVWcHpgNIqWA\nY17w1ByqYJNmxUmB2SBSAjjufQPCQ3WySbjiVMBsEGk8cOSb2dSHatSnvT6I+s+cDyKNBY6e\nNYOhKn6Gk8HPnExpkQa+R8hWpMSQGQxV8TOcDH7mZBBpFDAzXQZDFYiSv8IJkWI8RcrNlcFQ\nXRNnf4JTNog0GJj959lgqO4Q53yCUzbTi9Rpkp9I+ecMBkPVRZzpCU7ZFBdp2C7JTqQCT70N\nhurx26Jmd4JTNrMTadLPeCsCNxiqnqeOzOkEp2zmJ1JplS4VF/NZV0OIcznBKZu5ifSyIxZV\n6VyxFNRgqIYSZ3CCUzazFGm/ZUsRjxWLA8vl+SLt432CUzYzE+mlsQMpNPmfJWFnYMmIiLSP\n7QlO2cxXpFLT/1n6AIbBUCWJ1297NfiZk5mXSO3fcVLiEd5nsSdHZ2DhyIl0yKS/wgmRYiYW\naVNgb7LA35lS/gwng585mVmJdPuctJQJLy/6M6As0j4OJzhlswCRMo/wLP4xlRfJ4QSnbOYk\n0ksHcdQ2XOxp15NV1D3BKZuliDRCpeMN9OfeSKR9JE9wyqa8SINMKrkeD+d+0OYzOuDkJtI+\naic4ZbMkkTYDdkuX6+nPvaVI+wid4JTNfER66UfsteWa19Gfe1+R9tE4wSmbxYm0ebxbcntR\n3lykfZ5+glM2sxFp0FOazm3W+jv9uZ+DSPs88wSnbJYpUscjvKvv68/9bETa50knOGWzVJE2\nt3dLN76nP/fzEmmfh5/2ikgxxdZj1Oe/tzfVzU339KGqD1Sp2GETIsU8V6TWI7zb20xkqGoC\npSretgmRYkqtR+Jln9NWqvZvnz5Qr+L0Jzhlg0gHhe4/IJcbqumBohUnPcEpmxoidZhUaD2y\nr592Pa/VHKpJgcoVpzrBKRtEepQFAuUrTnCWWDazEKl5j+oz4AA0qIhIMYikCDSoiEgxZZ6E\nFicuHGhQEZFiEEkRaFARkWJKrEe8P/1Npg80qIhIMYikCDSouEyR7ptUYD046wGRBIJIj7JA\noEHFJYg05LFdfj04fQiRFIJIj7JAoEFFRIpJr8fVfelvMn2gQUVEikEkRaBBRUSKQSRFoEFF\nRIrJrgcfsTAF0KDiQkW6axIiKQINKiJSTHI9LH9bqT7QoCIixSCSItCgIiLF5NaDT8+aBmhQ\nEZFiEEkRaFBxESINOGyXWo+bn1iiv8n0gQYVESkGkRSBBhWXIVL/j7bLrAcfjDoV0KDiQkTq\nbRIiKQINKiJSTGI9+IThyYAGFREpBpEUgQYVESlm/Hrc+5Bh/U2mDzSoiEgxiKQINKhoL9Jn\nv7y0v/Hd84Z9c3UHhFwyiSudcd0j8VtYJgQaVLTfI/UMIjkDDSouVqQ7Jo1dj/u/z0h/k+kD\nDSoiUkzHenT+inhEmhJoUBGRYrpE6vg1evyCvUmBBhWXIlLfJ0n31+PlFuQuvQ9xZBYINKiI\nSDHdIt373a5dj/r0N5k+0KAiIsU8EOmOSog0LdCgIiLFPBTpljWdhyH0N5k+0KDickW6bdLd\n9Wjc/mqnhEgTAw0qIlJMH5HasE6PDDaZPtCgIiLF9BMp7pQQaWqgQUVEiukpUvPrbo8MNpk+\n0KAiIsXcW48bRxhe7v5VL+LoLBBoUBGRYvqLdFLpgUcGm0wfaFARkWKGiPTg3Q4PiKOzQKBB\nRUSKGSZS5/vvHhBHZ4FAg4oLFummSXfWY9TbVTuJ47NAoEFFRIoZLNLD6G8yfaBBRUSKQSRF\noEFFRIpBJEWgQUVEirm9HgmPDDaZPtCgIiLFIJIi0KAiIsUgkiLQoOKSRbplEiIpAg0qIlLM\nzfXIeGSwyfSBBhUXI1LPx3aIpAg0qIhIMYikCDSoiEgxiKQINKiISDG31iPlkcEm0wcaVESk\nGERSBBpUXLRIN0xCJEWgQcVlidRWopdIOY8MNpk+0KDiokS6OgsPkTyABhWXJNILeyRToEHF\nBYn0wkM7V6BBxQWJtBknUtIjg02mDzSouByRdkEkT6BBxWWJ1LYCkTyABhWXLdK1SYikCDSo\niEgxV+uR9chgk+kDDSoiUgwiKQINKiJSDCIpAg0qIlIMIikCDSoiUkx7PdIeGWwyfaBBRUSK\nQSRFoEHFhYt0ZRIiKQINKiJS9xUQSQFoUBGRWlcY8gvLe0V/k+kDDSoiUvz7z3gVRJIAGlRc\nmEiPjjZsRQpXQSQJoEFFRIp/jUiKQIOKSxepZdJOpMZ1CnhksMn0gQYVESn+7We4EiJpAA0q\nIlL8289wLUTSABpURKT4t5/haoikATSoiEjxLz+b1yvhkcEm0wcaVFykSE1B7oh087NSRkV/\nk+kDDSouXqSmSYgkCjSouESRXvqItLnxMXijor/J9IEGFRcp0p3HdrvvNtbj6gOOx0V/k+kD\nDSouTaSDRb1EKrNDMthk+kCDioh0X6Qy0d9k+kCDissT6eoowsmk/TeZAUWgQUVEQiR9oEHF\n5Yl0/uMURJIHGlRcpkjhbamIJA80qLg4kQ65iPRyEunwLWZAEWhQceEi7Y7hIZI80KCipUjr\n9L00zpM4mYRIukCDio4irRFpYUCDioYircvtkQ6H8L4b32EGFIEGFQ1FKvHQrnnwDpHkgQYV\n7UX6HJeX9p8vI0GE9MhUutxP/T1SOPWIf0wVgQYV7fdIIxPe4PCCSNpAg4qItEEkeaBBRUTa\n5vsFkaSBBhWXKlI4K+n7cjIsM6AINKiISJvd21YRSRpoUNFSpBIJ58lezpJlBhSBBhUXLFLj\npCRE0gYaVESkXRBJG2hQEZF2QSRtoEHFxYoUPrYOkbSBBhUXLFLjMiJpAw0qItI+Z5OYAUWg\nQcXlihSCSNJAg4qItA8iSQMNKiLSPogkDTSoiEj7IJI00KAiIh1yMokZUAQaVESkQxBJGWhQ\nEZEOQSRloEFFRDoEkZSBBhUR6ZijScyAItCgIiIdg0jCQIOKiHQMIgkDDSoi0jGIJAw0qIhI\npxxMYgYUgQYVEekURNIFGlREpFMQSRdoUBGRTkEkXaBBRUQ6BZF0gQYVEemcvUnMgCLQoCIi\nnYNIskCDioh0DiLJAg0qItI5iCQLNKiISJfsTGIGFIEGFRHpEkRSBRpURKRLEEkVaFARkS5B\nJFWgQUVEauSbGdAEGlREpEYQSRRoUBGRGkEkUaBBRURqBJFEgQYVEakRRBIFGlREpGa+mQFJ\noEFFRGoGkTSBBhURqRlE0gQaVESkZhBJE2hQEZFCvpkBRaBBRUQKQSRJoEFFRApBJEmgQUVE\nCkEkSaBBRUSK+X58lYHR32T6QIOKiBSDSIpAg4qIFINIikCDiogUg0iKQIOKiBTzWdwk/U2m\nDzSoiEgxiKQINKiISDGfxR/c6W8yfaBBRUSKQSRFoEFFRIr5LH68QX+T6QMNKiJSDCIpAg0q\nIlIMIikCDSoiUsxuPcqapL/J9IEGFREpBpEUgQYVESlmvx5FTdLfZPpAg4qIFINIikCDiogU\nc1iPkibpbzJ9oEFFRIpBJEWgQUVEikEkRaBBRUSKOa5HQZP0N5k+0KAiIsUgkiLQoCIixZzW\no5xJ+ptMH2hQ0V6kz2nyPRGXLDOTuNIZkT1SuV2S/r99+kCDivZ7pMJBJEWgQUVEikEkRaBB\nRUSKuaxHKZP0N5k+0KAiIsUgkiLQoCIixTTWo5BJ+ptMH2hQEZFiEEkRaFARkWKa61HGJP1N\npg80qIhIMYikCDSoiEgxYT2KmKS/yfSBBhURKQaRFIEGFREpJq5HCZP0N5k+0KAiIsW01qOA\nSfqbTB9oUBGRYhBJEWhQEZFi2uuRN0l/k+kDDSoiUszVeqRN0t9k+kCDiogUg0iKQIOKiBRz\nvR5Zk/Q3mT7QoCIixdxYj6RJ+ptMH2hQEZFiEEkRaFARkWJurUfOJP1Npg80qIhIMYikCDSo\niEgxN9cjZZL+JtMHGlREpJjb65ExSX+T6QMNKiJSDCIpAg0qIlLMnfVImKS/yfSBBhURKebe\neow3SX+T6X6KsvIAAAX4SURBVAMNKiJSDCIpAg0qIlLM3fUYbZL+JtMHGlREpJj76zHWJP1N\npg80qIhIMYikCDSoiEgxHesx0iT9TaYPNKiISDFd6zHOJP1Npg80qIhIMZ3rMcok/U2mDzSo\niEgx3evxPUIl/U2mDzSoiEgxj9ZjuEn6m0wfaFARkWIersdgk/Q3mT7QoCIixTxej6Em6W8y\nfaBBRUSK6bEeA03S32T6QIOKiBTTZz2GmaS/yfSBBhURKabXegwySX+T6QMNKiJSTL/1GHIY\nXH+T6QMNKiJSTN/16G+S/ibTBxpURKSY3uvR2yT9TaYPNKiISDH916OvSfqbTB9oUBGRYgas\nR0+T9DeZPtCgIiLFDFmPfibpbzJ9oEFFRIoZtB69Dt7pbzJ9oEFFRIoZuB49TNLfZPpAg4qI\nFDN0PR6bpL/J9IEGFREpZvB6fLeTJj7KAoEGFREpJr8eV2bdkCsV/RlAJIHYi3SLWNQn/RlA\nJIHMUqRjyuikPwOIJJA5i3RIdvekPwOIJJD5i3TMaJ9KVLz1RK7cczlEEshiRDpm+Aj3f1/t\n/dwBFlILkQSyNJGOGTC2EdjXlpENR1ERSSALFemQe7NawJZCDXuphUgCWbRIx/R9JFYoWeAk\ndsfI/czTA7NBpBkAi6tl8DOXBmaDSLMEJtWy/JmfG0RaCHCQWjP5mWsGkRYL7FBLpWJFYDaI\nBPCc6Q5j6P7MpYJIADuIpdQy+JmTQSSAg4jj1DL4mZNBJIBJYh+1DH7mZBAJYHHitVoGP3My\nj0VabzPZ3cvNAMBJiMUPY/iJtD7/MUUMZmCBwBoVk2ohUozlDMwe+JyKg9RCpJiZzMDMgCoV\nO9SyF+mTkOflcvSiOxMacyfskQBWIOoDs0EkgBWI+sBsEAlgBaI+MBtEAliBqA/MBpEAViDq\nA7PhnQ0AKxD1gdnwXjuAFYj6wGwQCWAFoj4wG0QCWIGoD8wGkQBWIOoDs0EkgBWI+sBsEAlg\nBaI+MBtEAliBqA/MBpEAViDqA7NBJIAViPrAbBAJYAWiPjAbRAJYgagPzAaRAFYg6gOzQSSA\nFYj6wGwQCWAFoj4wG0QCWIGoD8wGkQBWIOoDs0EkgBWI+sBsEAlgBaI+MBtEAliBqA/MBpEA\nViDqA7NBJIAViPrAbBAJYAWiPjAbRAJYgagPzAaRAFYg6gOzQSSAFYj6wGwQCWAFoj4wG0QC\nWIGoD8zmySIRMo8gEiEFgkiEFAgiEVIgiERIgSASIQWCSIQUCCIRUiCIREiBIBIhBTILkZq/\neP10eT3pb2MfmnbD9WbiXxc/PI0662ZFqY6XS43N/LQ6zcxBpPX5j8ZljeU9ptnwqqlGrurI\nLeLOmvOl4x86i4hINWIokli9XdYbRJo0t/4xlVjcc65U3yjNwD63RNJpdwwiTZqbIsk8eN4l\niHR6/tH4nkBadQSfZ24QaeLc/cdUYoV3ufXgU6vhbZHi954fRJo0Nx/et7733Nx98CnT8KZI\nrUvPDyJNGv0ZsBPp1j9LAkGkSXNrBnRWeBe7h3aKi7hBpIlz7+CyxALv0xZJ71ncXZF0Gm4Q\naeqcX+bexBfln1yrkUZDvRflD2lWbB5hfF6j6zT8VlvEWYhEyLODSIQUCCIRUiCIREiBIBIh\nBYJIhBQIIhFSIIhESIEgEiEFgkjPyvtx6b9Wr6vDxbfV6s8TC5FMEOlJeT/as/m9+nm4iEfO\nQaTn5MfqJNLb6t/+4ttq/fHUSiQTRHpK1uu/J5FW683uIh55B5GekvfN5ijSn9X77uLb6u3J\nlUgqiPSsHEX6sfq7vbherX4/uQ9JBZGelaNI20d224s7k3hk5xxEelYOIv1d/dhdfN8+tnt9\ndiOSCCI9KweR3neHvHcXP9Y7pYhrEOlZOYi0Xp0u/uVpknMQ6VnZ2/Ox3w0dnPrF0yTjINKz\nsrfn5/7NDOcDeBwCtw0iPSt7e15X54ub3Yuy708sRDJBJEIKBJEIKRBEIqRAEImQAkEkQgoE\nkQgpEEQipEAQiZACQSRCCgSRCCkQRCKkQBCJkAL5H+1jfPb9TBFnAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the training and testing error\n",
    "error.reshape <- melt(error, id='K') # reshape for visualization, into a long format\n",
    "names(error.reshape) <- c('K', 'type', 'error') #rename the column for convenience in a plot\n",
    "\n",
    "#Error plot\n",
    "ggplot(data=error.reshape, aes(x=1/K, y=error, color=type)) + geom_line() +\n",
    "       scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +\n",
    "       ggtitle(\"Sum of Square of Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bad0d2",
   "metadata": {},
   "source": [
    "Report\t(in\tyour\t Jupyter\tNotebook\t file)\tthe\toptimum\tvalue\t for\tK\tin\tterms of the\ttesting\terror. Discuss the\tvalues\tof\tK\tcorresponding\tto\tunderfitting and overfitting based\ton\tyour\tplot\tin the\tprevious\tpart\t(Part\tII)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c53000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11"
      ],
      "text/latex": [
       "11"
      ],
      "text/markdown": [
       "11"
      ],
      "text/plain": [
       "[1] 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Find the optimal K value for the model by identifying the minimal value of test_error\n",
    "Min_error<-min(error.reshape[error.reshape$type==\"test\",\"error\"])\n",
    "Optimal_K <- error.reshape[error.reshape$type==\"test\" & error.reshape$error == Min_error,\"K\"]\n",
    "Optimal_K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ecb014",
   "metadata": {},
   "source": [
    "Based on the result, it seems that when the value of K is setting to 11 the model will perform with the least error for the testing set. Also, the plot illustrates that when the K value is less than 11 it will be over-fitting (the model is too complex with k<11). On the other hand, if the K value is more than 11 it will be under-fitting (the model is not complex enough when k>11).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf00459",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62d5c4",
   "metadata": {},
   "source": [
    "All of the code and the algorithm idea is derieved from:\n",
    "\n",
    "- Jupyter Notebooks:FIT5201 Machine Learning, (nd.). $\\textit{Activity 1.1 K-nearest neighbour classifier}$. https://lms.monash.edu/mod/resource/view.php?id=10048617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
