{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93d7ed1",
   "metadata": {},
   "source": [
    "### Implementation of K-Fold Cross Validation on KNN regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc73df7",
   "metadata": {},
   "source": [
    "In this question, it will be focused on the using k-fold cross-validation, which is an approach using for model selection on KNN regressor. The process will be proceed as the following (the initial step will be the similar as the previous question): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e970cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n"
     ]
    }
   ],
   "source": [
    "#Import the library\n",
    "library(reshape2) #For reshape the file\n",
    "library(ggplot2) #For data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a547b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the training and testing csv file\n",
    "train <- read.csv('Task1A_train.csv')\n",
    "test <- read.csv('Task1A_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33adc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the dataset by separate the actual result and the predictor\n",
    "train_data = as.matrix(train[,-2]) \n",
    "train_label = as.matrix(train[,2])\n",
    "test_data = as.matrix(test[,-2])\n",
    "test_label = as.matrix(test[,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0898e",
   "metadata": {},
   "source": [
    "1.Implement\t a\t L-Fold\t Cross\t Validation\t (CV)\t function\t for\t your\t KNN\n",
    "regressor:\n",
    "cv(train.data,\ttrain.label,\tnumFold=10)\n",
    "which\ttakes\tthe\ttraining\tdata\tand\ttheir\tlabels\t(continuous\tvalues),\tthe\n",
    "number\tof folds,\tand\treturns\terrors\tfor\tdifferent\tfolds\tof\tthe\ttraining\tdata.\n",
    "\n",
    "To implement the cross-validation technique, the knn classifier need to be created with same approach as the question one (create a knn regression which return the mean of point and k-value, and create a mse function) as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f3b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derieved the KNN function from the tutorial activity 1\n",
    "# KNN function (distance should be one of euclidean, maximum, manhattan, canberra, binary or minkowski)\n",
    "knnCV <- function(train.data, train.label, test.data, K=3, distance = 'euclidean'){\n",
    "    ## count number of train and test samples\n",
    "    train.len <- nrow(train.data)\n",
    "    test.len <- nrow(test.data)\n",
    "    \n",
    "    ## calculate distances between samples\n",
    "    dist <- as.matrix(dist(rbind(test.data, train.data), method= distance))[1:test.len, (test.len+1):(test.len+train.len)]\n",
    "    \n",
    "    test.label <- as.matrix(nrow(test.data))\n",
    "    ## for each test sample...\n",
    "    for (i in 1:test.len){\n",
    "        ### ...find its K nearest neighbours from training sample...\n",
    "        nn <- as.data.frame(sort(dist[i,], index.return = TRUE))[1:K,2]\n",
    "        \n",
    "        ###... and calculate mean\n",
    "        test.label[i] <- mean(train.label[nn])\n",
    "    }\n",
    "    \n",
    "    ## return the class labels as output\n",
    "    return (test.label)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00926fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean square error of the regression mean(y_real-y_pred)**2\n",
    "mse <- function(a,b){\n",
    "    mse = sum((a - b)^2/ nrow(b))\n",
    "    return(mse)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7904e8",
   "metadata": {},
   "source": [
    "Once all the necessary function is created, the cross-validation function will be created based on the following approach:\n",
    "\n",
    "1. Dividing the dataset into k-equal size distinct subset\n",
    "2. These subset will be divided into training set and validation set, which most of the set will be training set and 1 validation set (example 9 training set (k-1 set) and 1 validation set (1/k set))\n",
    "3. The second process will be repeated based on number of k-fold to ensure that all the data points are used for both training set and validation set\n",
    "4. The average of the validation error of each fold will be used for estimating testing error (Chen,2022)\n",
    "\n",
    "This is how it is implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9f87e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation Function\n",
    "cv <- function(train.data,train.label,KF=3,numFold=10){\n",
    "    #Create dataframe for storing k-fold and test accuracy\n",
    "    cross.test <- data.frame('K'=rep(0,numFold),'test'=rep(0,numFold))\n",
    "    #Iteration for creating K-1 training and a testing set\n",
    "    for (k in 1:numFold){\n",
    "        #index for the training set and validation set in k-fold cross validation(for dividing \n",
    "        #a dataset into training and validation set)\n",
    "        index <- (((k-1)*nrow(train.data)/numFold)+1):((k*nrow(train.data))/numFold) #k-1 training set and 1/k validation set\n",
    "        #Create a training set and validation per fold validation\n",
    "        train.set <- as.matrix(train.data[-index,])\n",
    "        train.lab <- as.matrix(train.label[-index,])\n",
    "        test.set <- as.matrix(train.data[index,])\n",
    "        test.lab <- as.matrix(train.label[index,])\n",
    "        #Save value to the cross.test dataframe\n",
    "        cross.test[k,'K'] <- k\n",
    "        ### Apply KNN regressor and Store the error from the KNN regressor function to cross.test\n",
    "        cross.test[k,'test'] <- mse(knnCV(train.set, train.lab, test.set, KF),test.lab)\n",
    "    }\n",
    "    #Return dataframe\n",
    "    return(cross.test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d92b4f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>K</th><th scope=col>test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1        </td><td>0.01710278</td></tr>\n",
       "\t<tr><td> 2        </td><td>0.01652778</td></tr>\n",
       "\t<tr><td> 3        </td><td>0.02490556</td></tr>\n",
       "\t<tr><td> 4        </td><td>0.08063889</td></tr>\n",
       "\t<tr><td> 5        </td><td>0.23397500</td></tr>\n",
       "\t<tr><td> 6        </td><td>0.52177500</td></tr>\n",
       "\t<tr><td> 7        </td><td>0.55035000</td></tr>\n",
       "\t<tr><td> 8        </td><td>0.66915000</td></tr>\n",
       "\t<tr><td> 9        </td><td>1.76782500</td></tr>\n",
       "\t<tr><td>10        </td><td>6.30945000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " K & test\\\\\n",
       "\\hline\n",
       "\t  1         & 0.01710278\\\\\n",
       "\t  2         & 0.01652778\\\\\n",
       "\t  3         & 0.02490556\\\\\n",
       "\t  4         & 0.08063889\\\\\n",
       "\t  5         & 0.23397500\\\\\n",
       "\t  6         & 0.52177500\\\\\n",
       "\t  7         & 0.55035000\\\\\n",
       "\t  8         & 0.66915000\\\\\n",
       "\t  9         & 1.76782500\\\\\n",
       "\t 10         & 6.30945000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| K | test |\n",
       "|---|---|\n",
       "|  1         | 0.01710278 |\n",
       "|  2         | 0.01652778 |\n",
       "|  3         | 0.02490556 |\n",
       "|  4         | 0.08063889 |\n",
       "|  5         | 0.23397500 |\n",
       "|  6         | 0.52177500 |\n",
       "|  7         | 0.55035000 |\n",
       "|  8         | 0.66915000 |\n",
       "|  9         | 1.76782500 |\n",
       "| 10         | 6.30945000 |\n",
       "\n"
      ],
      "text/plain": [
       "   K  test      \n",
       "1   1 0.01710278\n",
       "2   2 0.01652778\n",
       "3   3 0.02490556\n",
       "4   4 0.08063889\n",
       "5   5 0.23397500\n",
       "6   6 0.52177500\n",
       "7   7 0.55035000\n",
       "8   8 0.66915000\n",
       "9   9 1.76782500\n",
       "10 10 6.30945000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cross-validation 10 error from 10 fold\n",
    "cv(train_data,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22cfa08",
   "metadata": {},
   "source": [
    "2. Using\t the\t training\t data in\t Question\t 1,\t run\t your\t L-Fold\t CV\t where\tthe numFold\tis\tset\tto\t10.\tChange the\tvalue\tof\tK=1,..,20 in\tyour\tKNN\tregressor, and\tfor\teach\tK\tcompute\tthe\taverage\t10\terror\tnumbers\tyou\thave got.Plot the average error\tnumbers\tversus\t1/K for\tK=1,..,20 in\tyour\tKNN\tregressor.\n",
    "Save the plot in your Jupyter Notebook file\tfor\tQuestion 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2541c9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>K</th><th scope=col>Testing</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1      </td><td>0.586520</td></tr>\n",
       "\t<tr><td> 2      </td><td>0.809465</td></tr>\n",
       "\t<tr><td> 3      </td><td>1.019170</td></tr>\n",
       "\t<tr><td> 4      </td><td>1.232728</td></tr>\n",
       "\t<tr><td> 5      </td><td>1.511290</td></tr>\n",
       "\t<tr><td> 6      </td><td>1.822983</td></tr>\n",
       "\t<tr><td> 7      </td><td>2.216570</td></tr>\n",
       "\t<tr><td> 8      </td><td>2.473662</td></tr>\n",
       "\t<tr><td> 9      </td><td>2.895491</td></tr>\n",
       "\t<tr><td>10      </td><td>3.166623</td></tr>\n",
       "\t<tr><td>11      </td><td>3.524957</td></tr>\n",
       "\t<tr><td>12      </td><td>3.769219</td></tr>\n",
       "\t<tr><td>13      </td><td>4.243626</td></tr>\n",
       "\t<tr><td>14      </td><td>4.513951</td></tr>\n",
       "\t<tr><td>15      </td><td>5.000394</td></tr>\n",
       "\t<tr><td>16      </td><td>5.347379</td></tr>\n",
       "\t<tr><td>17      </td><td>5.838723</td></tr>\n",
       "\t<tr><td>18      </td><td>6.250302</td></tr>\n",
       "\t<tr><td>19      </td><td>6.825093</td></tr>\n",
       "\t<tr><td>20      </td><td>7.283268</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " K & Testing\\\\\n",
       "\\hline\n",
       "\t  1       & 0.586520\\\\\n",
       "\t  2       & 0.809465\\\\\n",
       "\t  3       & 1.019170\\\\\n",
       "\t  4       & 1.232728\\\\\n",
       "\t  5       & 1.511290\\\\\n",
       "\t  6       & 1.822983\\\\\n",
       "\t  7       & 2.216570\\\\\n",
       "\t  8       & 2.473662\\\\\n",
       "\t  9       & 2.895491\\\\\n",
       "\t 10       & 3.166623\\\\\n",
       "\t 11       & 3.524957\\\\\n",
       "\t 12       & 3.769219\\\\\n",
       "\t 13       & 4.243626\\\\\n",
       "\t 14       & 4.513951\\\\\n",
       "\t 15       & 5.000394\\\\\n",
       "\t 16       & 5.347379\\\\\n",
       "\t 17       & 5.838723\\\\\n",
       "\t 18       & 6.250302\\\\\n",
       "\t 19       & 6.825093\\\\\n",
       "\t 20       & 7.283268\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| K | Testing |\n",
       "|---|---|\n",
       "|  1       | 0.586520 |\n",
       "|  2       | 0.809465 |\n",
       "|  3       | 1.019170 |\n",
       "|  4       | 1.232728 |\n",
       "|  5       | 1.511290 |\n",
       "|  6       | 1.822983 |\n",
       "|  7       | 2.216570 |\n",
       "|  8       | 2.473662 |\n",
       "|  9       | 2.895491 |\n",
       "| 10       | 3.166623 |\n",
       "| 11       | 3.524957 |\n",
       "| 12       | 3.769219 |\n",
       "| 13       | 4.243626 |\n",
       "| 14       | 4.513951 |\n",
       "| 15       | 5.000394 |\n",
       "| 16       | 5.347379 |\n",
       "| 17       | 5.838723 |\n",
       "| 18       | 6.250302 |\n",
       "| 19       | 6.825093 |\n",
       "| 20       | 7.283268 |\n",
       "\n"
      ],
      "text/plain": [
       "   K  Testing \n",
       "1   1 0.586520\n",
       "2   2 0.809465\n",
       "3   3 1.019170\n",
       "4   4 1.232728\n",
       "5   5 1.511290\n",
       "6   6 1.822983\n",
       "7   7 2.216570\n",
       "8   8 2.473662\n",
       "9   9 2.895491\n",
       "10 10 3.166623\n",
       "11 11 3.524957\n",
       "12 12 3.769219\n",
       "13 13 4.243626\n",
       "14 14 4.513951\n",
       "15 15 5.000394\n",
       "16 16 5.347379\n",
       "17 17 5.838723\n",
       "18 18 6.250302\n",
       "19 19 6.825093\n",
       "20 20 7.283268"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculate average of each k-fold when he k is change 1 to 20\n",
    "knn_CV <- data.frame('K'=1:20, 'Testing'=rep(0,20))\n",
    "for (k in 1:20){\n",
    "    score=cv(train_data, train_label,KF=k)\n",
    "    knn_CV[k,'Testing']=mean(score[,2])\n",
    "}\n",
    "\n",
    "#Calculate the average error for each k\n",
    "knn_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b60ac7",
   "metadata": {},
   "source": [
    "### The plot of k-fold cross-validation knn error of 10 numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b0aaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaAAAAJYCAMAAACjGLEAAAAAM1BMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=5) # area of display\n",
    "\n",
    "ggplot(data=knn_CV, aes(x=1/K, y=Testing)) + geom_line() +\n",
    "       scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +\n",
    "       ggtitle(\"Missclassification Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b4a002",
   "metadata": {},
   "source": [
    "Report\t(in\tyour\tJupyter\tNotebook\tfile)\tthe\toptimum\tvalue\tfor\tK\tbased\ton\n",
    "your\tplot\tfor\tthis\t10-fold\tcross\tvalidation\tin\tthe\tprevious\tpart\t(Part\tII)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71dd7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Find the optimal K value for \n",
    "Min_error<-min(knn_CV$Testing)\n",
    "Optimal_K <- knn_CV[knn_CV$Testing == Min_error,\"K\"]\n",
    "Optimal_K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63371caa",
   "metadata": {},
   "source": [
    "Based on the optimal value and the plot, the optimal value of K for the k-fold cross validation of knn regressor is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab318135",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd5e28",
   "metadata": {},
   "source": [
    "All of the code and the algorithm idea is derieved from:\n",
    "\n",
    "- Chen, B. (2022). $\\textit{Week 1.:Elements of Machine Learning}$ \\[PowerPoint slides]. https://lms.monash.edu/mod/resource/view.php?id=9894948 \n",
    "- Jupyter Notebooks:FIT5201 Machine Learning, (nd.). $\\textit{Activity 1.1 K-nearest neighbour classifier}$. https://lms.monash.edu/mod/resource/view.php?id=10048617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ce1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
